# 최적화 학습 프로젝트 구현 계획서

## 개요
이 프로젝트는 최적화 알고리즘을 학습하기 위한 코드입니다.
결정론적 방법과 확률론적 방법을 구분하여 구현하고, 다양한 벤치마크 함수를 통해 성능을 평가합니다.

---

## 1. 최적화 방법 요약

### 1.1 결정론적 최적화 방법 (Deterministic Methods)

| 번호 | 방법명 | 영문명 | 설명 | 장점 | 단점 | 구현 상태 |
|:---:|:------|:------|:-----|:-----|:-----|:--------:|
| 1 | 경사 하강법 | Gradient Descent | 목적 함수의 그래디언트(기울기) 반대 방향으로 이동하여 최솟값을 탐색하는 가장 기본적인 방법 | 단순하고 이해하기 쉬움, 메모리 효율적 | 학습률에 민감, 수렴 속도 느림, 지역 최솟값에 갇힐 수 있음 | ✅ 완료 |
| 2 | 뉴턴 방법 | Newton's Method | 2차 도함수(헤시안)을 활용하여 2차 테일러 근사를 통해 빠르게 수렴하는 방법 | 빠른 수렴 속도 (2차 수렴), 수렴 근처에서 매우 정확 | 헤시안 계산 비용 높음, 특이 행렬 문제, 초기점 의존 | ✅ 완료 |
| 3 | BFGS | BFGS (Quasi-Newton) | 헤시안의 역행렬을 점진적으로 근사하여 뉴턴법의 계산 비용을 줄인 준뉴턴 방법 | 실용적이고 강건함, 헤시안 계산 불필요, 빠른 수렴 | 메모리 사용량 O(n²), 대규모 문제에 부적합 | ✅ 완료 |

### 1.2 확률론적 최적화 방법 (Stochastic Methods)

| 번호 | 방법명 | 영문명 | 설명 | 장점 | 단점 | 구현 상태 |
|:---:|:------|:------|:-----|:-----|:-----|:--------:|
| 1 | 유전 알고리즘 | Genetic Algorithm | 자연선택과 유전학의 원리(선택, 교차, 돌연변이)를 모방한 진화 기반 최적화 | 전역 탐색 능력 우수, 미분 불필요, 다목적 최적화 가능 | 수렴 속도 느림, 파라미터 튜닝 필요, 계산 비용 높음 | ✅ 완료 |
| 2 | 입자 군집 최적화 | Particle Swarm Optimization | 새나 물고기 떼의 군집 지능을 모방, 입자들이 개인/전역 최적을 향해 이동 | 구현 간단, 파라미터 적음, 빠른 수렴, 병렬화 용이 | 조기 수렴 가능, 고차원에서 성능 저하 | ✅ 완료 |
| 3 | 담금질 기법 | Simulated Annealing | 금속의 열처리 냉각 과정을 모방, 온도에 따른 확률적 수락으로 지역 최솟값 탈출 | 지역 최솟값 탈출 가능, 전역 최적 보장(이론적), 구현 간단 | 수렴 속도 느림, 냉각 스케줄 설정 어려움 | ✅ 완료 |
| 4 | 차분 진화 | Differential Evolution | 벡터 차분을 활용한 돌연변이와 교차 연산을 통한 진화 알고리즘 | 연속 최적화에 강력, 강건함, 파라미터 적음 | 이산 문제에 부적합, 수렴 불안정 가능 | ✅ 완료 |

---

## 2. 벤치마크 함수 요약

### 2.1 볼록 함수 (Convex Functions)

| 번호 | 함수명 | 수식 | 전역 최솟값 | 탐색 범위 | 특징 | 구현 상태 |
|:---:|:------|:-----|:-----------|:---------|:-----|:--------:|
| 1 | Sphere | f(x) = Σ(xᵢ²) | f(0,...,0) = 0 | [-5.12, 5.12] | 가장 단순한 볼록 함수, 기본 성능 테스트용 | ✅ 완료 |
| 2 | Rosenbrock | f(x) = Σ[100(xᵢ₊₁-xᵢ²)² + (1-xᵢ)²] | f(1,...,1) = 0 | [-5, 10] | 좁고 포물선형 골짜기, 수렴 어려움 | ✅ 완료 |

### 2.2 다봉 함수 (Multimodal Functions)

| 번호 | 함수명 | 수식 | 전역 최솟값 | 탐색 범위 | 특징 | 구현 상태 |
|:---:|:------|:-----|:-----------|:---------|:-----|:--------:|
| 1 | Rastrigin | f(x) = 10n + Σ[xᵢ²-10cos(2πxᵢ)] | f(0,...,0) = 0 | [-5.12, 5.12] | 많은 지역 최솟값, 전역 탐색 능력 테스트 | ✅ 완료 |
| 2 | Ackley | f(x) = -20exp(...) - exp(...) + 20 + e | f(0,...,0) = 0 | [-5, 5] | 중앙 급격한 구멍, 평평한 바깥 영역 | ✅ 완료 |
| 3 | Griewank | f(x) = Σ(xᵢ²/4000) - Πcos(xᵢ/√i) + 1 | f(0,...,0) = 0 | [-600, 600] | 넓은 범위 진동, 고차원 쉬워짐 | ✅ 완료 |

### 2.3 골짜기/고원 함수 (Valley/Plateau Functions)

| 번호 | 함수명 | 수식 | 전역 최솟값 | 탐색 범위 | 특징 | 구현 상태 |
|:---:|:------|:-----|:-----------|:---------|:-----|:--------:|
| 1 | Beale | f(x,y) = (1.5-x+xy)² + ... | f(3, 0.5) = 0 | [-4.5, 4.5] | 날카롭고 좁은 골짜기 (2차원) | ✅ 완료 |
| 2 | Booth | f(x,y) = (x+2y-7)² + (2x+y-5)² | f(1, 3) = 0 | [-10, 10] | 완만한 골짜기 (2차원) | ✅ 완료 |
| 3 | Himmelblau | f(x,y) = (x²+y-11)² + (x+y²-7)² | 4개 최솟값 = 0 | [-5, 5] | 4개의 동일한 전역 최솟값 (2차원) | ✅ 완료 |

---

## 3. 개발 진행 상태

| 단계 | 작업 내용 | 상태 | 완료일 |
|:---:|:---------|:----:|:-----:|
| 1단계 | 벤치마크 함수 구현 | ✅ 완료 | 2026-01-15 |
| 2단계 | 결정론적 최적화 방법 구현 | ✅ 완료 | 2026-01-15 |
| 3단계 | 확률론적 최적화 방법 구현 | ✅ 완료 | 2026-01-15 |
| 4단계 | 시각화 및 평가 도구 구현 | ✅ 완료 | 2026-01-15 |
| 5단계 | 실험 및 비교 분석 | ⏳ 대기 | - |

---

## 4. 성능 평가 지표

| 지표 | 영문명 | 설명 |
|:-----|:------|:-----|
| 수렴 횟수 | Iterations | 목표 정확도에 도달하기까지의 반복 횟수 |
| 계산 시간 | Execution Time | 최적화 실행에 소요된 시간 (초) |
| 최종 오차 | Final Error | 찾은 최적값과 실제 최적값의 차이 |
| 위치 오차 | Point Error | 찾은 최적점과 실제 최적점의 거리 |
| 성공률 | Success Rate | 전역 최적해에 도달한 비율 (확률론적 방법) |

---

## 5. 프로젝트 정보
- **시작일**: 2026-01-15
- **현재 단계**: 5단계 (실험 및 비교 분석)
- **작업 폴더**: `C:\Users\1209s\.antigravity\HW\optimization_study\`
